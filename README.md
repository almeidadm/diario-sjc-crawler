# üìò Di√°rio SJC Crawler

![Python Version](https://img.shields.io/badge/python-3.12+-blue.svg)
![Packaging: Poetry](https://img.shields.io/badge/packaging-poetry-cyan.svg)
![Async/Await](https://img.shields.io/badge/async-await-green.svg)
![License: MIT](https://img.shields.io/badge/license-MIT-lightgrey.svg)


Di√°rio SJC Crawler √© um crawler ass√≠ncrono multi-munic√≠pio para coleta estruturada de Di√°rios Oficiais no Brasil.
A aplica√ß√£o √© baseada no formato de disponibiliza√ß√£o dos Di√°rios Oficiais fornecido pela IONews (https://ionews.com.br/), cuja publica√ß√£o segue um modelo hier√°rquico em HTML, permitindo extra√ß√£o sistem√°tica de se√ß√µes, categorias e conte√∫do textual.

Ele foi projetado para uso em pipelines de ETL, RAG e an√°lise documental em larga escala.

**Exemplo:**

- S√£o Jos√© dos Campos: https://diariodomunicipio.sjc.sp.gov.br/

---

## A aplica√ß√£o fornece:

Coleta paralela de edi√ß√µes por per√≠odo ou janela m√≥vel.

Armazenamento local ou em MinIO/S3 com particionamento.

Suporte opcional a DuckDB para consultas r√°pidas.

CLI robusto para orquestra√ß√£o de crawlers espec√≠ficos por munic√≠pio.

A interface oficial do projeto √© fornecida via entrypoint Poetry:

```bash
cli  # mapeado para diario_crawler.cli.run_crawler:main
```

---

## üöÄ Instala√ß√£o

```bash
git clone https://github.com/almeidadm/diario-sjc-crawler
cd diario-sjc-crawler
poetry install
```

---

## üß≠ Uso B√°sico

Liste os crawlers dispon√≠veis:

```bash
cli --list-crawlers
```
Execute para um munic√≠pio espec√≠fico (√∫ltimos 7 dias):
```bash
cli --municipality sp_sao_jose_dos_campos --days 7
```
Baixe um per√≠odo espec√≠fico e salve no MinIO:
```bash
cli \
  --municipality rj_rio_de_janeiro \
  --start-date 2025-01-01 \
  --end-date 2025-01-31 \
  --storage minio
```

Migrar dados locais para MinIO:
```bash
cli --municipality sp_sao_jose_dos_campos --migrate-to-minio
```

---

## ‚öôÔ∏è Principais Par√¢metros

Munic√≠pio

```bash
--municipality {sp_sao_jose_dos_campos,rj_rio_de_janeiro,es_associacao_municipios,ro_jaru,ms_corumba}
```

Janela temporal

- --start-date YYYY-MM-DD

- --end-date YYYY-MM-DD

- --days N (padr√£o: 7)

Concorr√™ncia e desempenho

- --batch-size (padr√£o: 30)

- --max-concurrent (padr√£o: 10)

Armazenamento

Local, MinIO ou S3 (--storage)

- --output-dir para storage local

- --partition-by {day,month,year}

MinIO/S3

Inclui endpoint, bucket, credenciais e prefixos configur√°veis.

DuckDB

- --enable-duckdb

- --duckdb-path (arquivo ou in-memory)

## üìÇ Estrutura e Depend√™ncias

O projeto √© organizado como um pacote Poetry:

Pacote principal: diario_crawler/ (definido em [tool.poetry])

CLI: diario_crawler.cli.run_crawler

Depend√™ncias principais:

httpx[http2] para requisi√ß√µes ass√≠ncronas

selectolax para parsing HTML eficiente

pandas, polars, pyarrow, duckdb para processamento tabular

typer para a interface CLI

vcrpy para testes reprodut√≠veis

Ambiente de desenvolvimento inclui: pytest, flake8, black, isort, matplotlib, seaborn, entre outros.

## üß™ Testes

Execute toda a su√≠te:
```bash
task test
```

## üìÑ Licen√ßa
Este projeto est√° licenciado sob a MIT License.
Consulte o arquivo LICENSE para mais detalhes.
